'''
Copyright 2024 Jack Morgan

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
'''
import numpy as np
from hmmlearn import hmm

class ClassicalHMM:
    def __init__(self,
                 transition_matrix: list[list[float]]|np.ndarray = None, 
                 emission_matrix: list[list[float]]|np.ndarray = None, 
                 initial_probabilities: list[float]|np.ndarray = None,
                 ):
        """
        The function `classical_hmm` generates a sample sequence of observations and hidden states using a
        classical Hidden Markov Model (HMM) with specified transition, emission, and initial probability
        matrices.
        
        :param n_samples: The `n_samples` parameter in the `classical_hmm` function represents the number of
        observations to generate in each sample sequence. This parameter determines the length of the
        sequence of observations and hidden states that will be generated by the Hidden Markov Model (HMM)
        during sampling, defaults to 4 (optional)
        :param n_shots: The `n_shots` parameter in the `classical_hmm` function represents the number of
        times the Hidden Markov Model (HMM) will generate a sample sequence of observations and hidden
        states. In other words, it determines how many sample sequences will be generated by the HMM during
        the, defaults to 100 (optional)
        :param transition_matrix: The transition matrix defines the probabilities of transitioning between
        hidden states in a Hidden Markov Model (HMM). It is a square matrix where each element (i, j)
        represents the probability of transitioning from hidden state i to hidden state j
        :param emission_matrix: The `emission_matrix` in the Hidden Markov Model (HMM) represents the
        probabilities of observing each possible output symbol from each hidden state. It is a matrix where
        each row corresponds to a hidden state, and each column corresponds to an observation symbol
        :param initial_probabilities: The `initial_probabilities` parameter represents the initial
        probabilities of the hidden states in the Hidden Markov Model (HMM). These probabilities determine
        the likelihood of starting in each hidden state when the model is initialized
        :return: The function `classical_hmm` returns a dictionary `hist_dict` containing the frequency of
        each possible observation sequence generated by the Hidden Markov Model (HMM) based on the specified
        parameters. The keys of the dictionary represent the binary observation sequences, and the values
        represent the number of times each sequence was generated in the specified number of shots.
        """

        # Number of hidden states
        self.num_states = transition_matrix.shape[0]

        # Number of outcomes
        self.num_outcomes = emission_matrix.shape[1]

        # Generate a sample sequence of observations and hidden states
        self.num_outcome_digits = np.ceil(np.log2(self.num_outcomes))

        # Create a Multinomial HMM
        model = hmm.CategoricalHMM(n_components=self.num_states)

        # Set the model parameters
        model.startprob_ = initial_probabilities
        model.transmat_ = transition_matrix
        model.emissionprob_ = emission_matrix

        self.model = model

    def generate_distribution(self,
                              num_time_steps: int,
                              num_samples: int,
                              ):


        hist_dict = {str(format(i, f'0{int(self.num_outcome_digits*num_time_steps)}b')) : 0 for i in range(int(2**(self.num_outcome_digits*num_time_steps)))}

        for _ in range(num_samples):
            observations = self.model.sample(num_time_steps)[0]
            key = ''.join(str(format(bit[0], f'0{int(self.num_outcome_digits)}b')) for bit in reversed(observations))
            hist_dict[key] += 1

        return hist_dict

if __name__ == '__main__':

    t_matrix = np.array([
        [0.5, 0.1, 0.15, 0.25],
        [0.1, 0.5, 0.25, 0.15],
        [0.25, 0.15, 0.5, 0.1],
        [0.15, 0.25, 0.1, 0.5]
        ])

    e_matrix = np.array([
        [0.8, 0.2],
        [0.2, 0.8],
        [0.4, 0.6],
        [0.6, 0.4]
    ])

    i_probabilities = np.array([0.25, 0.25, 0.25, 0.25])

    test = classical_hmm(transition_matrix=t_matrix,
                         emission_matrix=e_matrix,
                         initial_probabilities=i_probabilities)
    
    dist = test.generate_distribution(num_time_steps = 4,
                                      num_samples = 1000)
    print(dist)
